{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3acf87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import nessesary library\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting directories to extract and store MRI volume \n",
    "\n",
    "path_to_raw_training_samples_from_source_domain = 'dataset/raw_dataset/training_data/source_sample/ceT1_MRI_scans/'\n",
    "path_to_raw_training_labels_from_source_domain = 'dataset/raw_dataset/training_data/source_sample/ceT1_MRI_labels/'\n",
    "path_to_raw_training_samples_from_target_domain = 'dataset/raw_dataset/training_data/target_sample/'\n",
    "path_to_raw_validation_samples_from_target_domain = 'dataset/raw_dataset/validation_data/' \n",
    "\n",
    "path_to_preprocessed_training_samples_from_source_domain = 'dataset/preprocessed_dataset/training_data/source_sample/ceT1_MRI_scans/'\n",
    "path_to_preprocessed_training_labels_from_source_domain = 'dataset/preprocessed_dataset/training_data/source_sample/ceT1_MRI_labels/'\n",
    "path_to_preprocessed_training_samples_from_target_domain = 'dataset/preprocessed_dataset/training_data/target_sample/'\n",
    "path_to_preprocessed_validation_samples_from_target_domain = 'dataset/preprocessed_dataset/validation_data/' \n",
    "\n",
    "path_to_raw_prediction_mask = 'prediction_mask/raw_prediction/'\n",
    "path_to_postprocessed_prediction_mask = 'prediction_mask/postprocessed_prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_from_source_domain = glob.glob(path_to_raw_training_samples_from_source_domain+'*')\n",
    "training_labels_from_source_domain = glob.glob(path_to_raw_training_labels_from_source_domain+'*')\n",
    "training_samples_from_target_domain = glob.glob(path_to_raw_training_samples_from_target_domain+'*')\n",
    "validation_samples_from_target_domain = glob.glob(path_to_raw_validation_samples_from_target_domain+'*')\n",
    "\n",
    "print('Number of training samples from source domain (ceT1) is: ' + str(len(training_samples_from_source_domain)))\n",
    "print('Number of training labels from source domain (ceT1) is: ' + str(len(training_labels_from_source_domain)))\n",
    "print('Number of training samples from target domain (hrT2) is: ' + str(len(training_samples_from_target_domain)))\n",
    "print('Number of validation samples from target domain (hrT2) is: ' + str(len(validation_samples_from_target_domain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339600b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random training sample from source domain (ceT1)\n",
    "img_load = nib.load(training_samples_from_source_domain[0]).get_fdata()\n",
    "labels_load = nib.load(training_labels_from_source_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,29+i])\n",
    "    plt.imshow(labels_load[:,:,29+i],alpha=0.5)\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random training sample from target domain (hrT2)\n",
    "img_load = nib.load(training_samples_from_target_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,29+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32207a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random validation sample from target domain (hrT2)\n",
    "img_load = nib.load(validation_samples_from_target_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,29+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49995bb3",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a75ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_volume(volume, interpolator = sitk.sitkLinear):\n",
    "    new_spacing = [0.6, 0.6, 1.0]\n",
    "    original_spacing = volume.GetSpacing()\n",
    "    original_size = volume.GetSize()\n",
    "    new_size = [int(round(osz*(ospc/nspc))) for osz,ospc,nspc in zip(original_size, original_spacing, new_spacing)]\n",
    "    return sitk.Resample(volume, new_size, sitk.Transform(), interpolator, volume.GetOrigin(), new_spacing, volume.GetDirection(), 0, volume.GetPixelID())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_z_range(training_image_load,labels_load):\n",
    "    nda = sitk.GetArrayFromImage(labels_load)\n",
    "    x = np.sum(nda,axis = (1,2))\n",
    "    x_arg = np.argwhere(x>0)\n",
    "    starting_layer_of_ROI = x_arg[0]\n",
    "    ending_layer_of_ROI = x_arg[-1]\n",
    "    expand = (120-len(x_arg))/2\n",
    "    \n",
    "    if expand >= starting_layer_of_ROI:\n",
    "        [cropped_starting_layer_of_ROI,cropped_ending_layer_of_ROI] = [0, 120]\n",
    "        \n",
    "    elif (expand + 1 + ending_layer_of_ROI) >= x.shape[0]:\n",
    "        [cropped_starting_layer_of_ROI,cropped_ending_layer_of_ROI] = [x.shape[0]-120, x.shape[0]]\n",
    "        \n",
    "    else:\n",
    "        cropped_starting_layer_of_ROI = int((s-np.floor(expand))[0])\n",
    "        cropped_ending_layer_of_ROI = int((e+np.ceil(expand)+1)[0])\n",
    "    \n",
    "    z_label_crop = labels_load[:,:,cropped_starting_layer_of_ROI:cropped_ending_layer_of_ROI]\n",
    "    z_image_crop = training_image_load[:,:,cropped_starting_layer_of_ROI:cropped_ending_layer_of_ROI]\n",
    "    return (z_image_crop,z_label_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_on_training_sample(img, center_x, center_y, label):\n",
    "    left = int(center_x - np.ceil(256/2))\n",
    "    bottom = int(center_y - np.ceil(256/2))\n",
    "    center_cropped_img = img[left:left+256, bottom:bottom+256, :]\n",
    "    if label is None:\n",
    "        return center_cropped_img\n",
    "    else:\n",
    "        center_cropped_label = label[left:left+256, bottom:bottom+256, :]\n",
    "        return (center_cropped_img, center_cropped_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_on_validation_sample(img, center_x, center_y):\n",
    "    left = int(center_x - np.ceil(368/2))\n",
    "    bottom = int(center_y - np.ceil(368/2))\n",
    "    center_cropped_img = img[left:left+368, bottom:bottom+368, :]\n",
    "    return center_cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_center_z_axis(image):\n",
    "    nda = sitk.GetArrayFromImage(image)\n",
    "    thrid_percentile = np.percentile(nda,75)\n",
    "    center_y = round(np.mean(np.argwhere(nda>=thrid_percentile)[:,1]))\n",
    "    center_x = round(np.mean(np.argwhere(nda>=thrid_percentile)[:,2]))\n",
    "    return (center_x,center_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_clustering(label_volume,target_label):\n",
    "    labels_load = sitk.GetArrayFromImage(label_volume)\n",
    "    label = np.zeros(labels_load.shape)\n",
    "    for j in range(labels_load.shape[0]):\n",
    "        label[j,:,:] = (labels_load[j,:,:] > 0.5)*target_label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image preprocessing on training samples from source domain (ceT1)\n",
    "for i in range(len(training_samples_from_source_domain)):\n",
    "    \n",
    "    save_path_for_preprocessed_training_samples_from_source_domain = path_to_preprocessed_training_samples_from_source_domain + 'crossmoda_'+str(i+1)+'_ceT1.nii'\n",
    "    save_path_for_preprocessed_training_labels_from_source_domain = path_to_preprocessed_training_labels_from_source_domain + 'crossmoda_'+str(i+1)+'_Label.nii'\n",
    "    \n",
    "    training_sample_volume = sitk.ReadImage(training_samples_from_source_domain[i])\n",
    "    training_label_volume = sitk.ReadImage(training_labels_from_source_domain[i])\n",
    "    \n",
    "    training_label_volume_nda = sitk.GetArrayFromImage(training_label_volume)\n",
    "    label_1 = np.zeros(training_label_volume_nda.shape)\n",
    "    label_2 = np.zeros(training_label_volume_nda.shape)\n",
    "    \n",
    "    for j in range(training_label_volume_nda.shape[0]):\n",
    "        label_1[j,:,:] = (training_label_volume_nda[j,:,:] == 1)*1\n",
    "        label_2[j,:,:] = (training_label_volume_nda[j,:,:] == 2)*1\n",
    "        \n",
    "    label_1_volume = sitk.GetImageFromArray(label_1, isVector=False)\n",
    "    label_1_volume.SetSpacing(training_label_volume.GetSpacing())\n",
    "    \n",
    "    label_2_volume = sitk.GetImageFromArray(label_2, isVector=False)\n",
    "    label_2_volume.SetSpacing(training_label_volume.GetSpacing())\n",
    "        \n",
    "    resampled_training_sample_from_source_domain = resample_volume(training_sample_volume)\n",
    "    \n",
    "    resampled_training_label_1_from_source_domain = resample_volume(label_1_volume)\n",
    "    resampled_training_label_2_from_source_domain = resample_volume(label_2_volume)\n",
    "    \n",
    "    resampled_training_clusterred_label_1_from_source_domain = label_clustering(resampled_training_label_1_from_source_domain,1)\n",
    "    resampled_training_clusterred_label_2_from_source_domain = label_clustering(resampled_training_label_2_from_source_domain,2)\n",
    "    \n",
    "    resampled_training_label_from_source_domain = resampled_training_clusterred_label_1_from_source_domain + resampled_training_clusterred_label_2_from_source_domain\n",
    "    resampled_training_label_from_source_domain = np.where(resampled_training_label_from_source_domain > 2, 1,resampled_training_label_from_source_domain)\n",
    "    resampled_training_label_from_source_domain = sitk.GetImageFromArray(resampled_training_label_from_source_domain, isVector=False)\n",
    "    resampled_training_label_from_source_domain.SetSpacing(resampled_training_label_from_source_domain.GetSpacing())\n",
    "    \n",
    "    (center_x,center_y) = finding_center_z_axis(resampled_training_sample_from_source_domain)\n",
    "    (center_cropped_img, center_cropped_label) = center_crop_on_training_sample(resampled_training_sample_from_source_domain, center_x, center_y, label=resampled_training_label_from_source_domain)\n",
    "    (cropped_training_sample_from_source_domain, cropped_training_label_from_source_domain) = get_new_z_range(center_cropped_img,center_cropped_label)\n",
    "\n",
    "    normalised_training_sample_from_source_domain = sitk.RescaleIntensity(cropped_training_sample_from_source_domain,outputMinimum=0.0, outputMaximum=255.0)\n",
    "\n",
    "    sitk.WriteImage(normalised_training_sample_from_source_domain, save_path_for_preprocessed_training_samples_from_source_domain)\n",
    "    sitk.WriteImage(cropped_training_label_from_source_domain, save_path_for_preprocessed_training_labels_from_source_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12aaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image preprocessing on training labels from target domain (hrT2)\n",
    "for i in range(len(training_samples_from_target_domain)):\n",
    "    \n",
    "    save_path_for_preprocessed_training_samples_from_target_domain = path_to_preprocessed_training_samples_from_target_domain + 'crossmoda_'+str(i+106)+'_hrT2.nii'\n",
    "    \n",
    "    training_sample_volume = sitk.ReadImage(training_samples_from_target_domain[i])\n",
    "    resampled_training_sample_from_target_domain = resample_volume(training_sample_volume)\n",
    "    \n",
    "    (center_x,center_y) = finding_center_z_axis(resampled_training_sample_from_target_domain)\n",
    "    cropped_training_sample_from_target_domain = center_crop_on_training_sample(resampled_training_sample_from_target_domain, center_x, center_y, label = None)\n",
    "\n",
    "    normalised_training_sample_from_target_domain = sitk.RescaleIntensity(cropped_training_sample_from_target_domain,outputMinimum=0.0, outputMaximum=255.0)\n",
    "    sitk.WriteImage(normalised_training_sample_from_target_domain, save_path_for_preprocessed_training_samples_from_target_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image preprocessing on validation samples from target domain (hrT2)\n",
    "for i in range(len(validation_samples_from_target_domain)):\n",
    "    \n",
    "    save_path_for_preprocessed_validation_samples_from_target_domain = path_to_preprocessed_validation_samples_from_target_domain + 'crossmoda_'+str(i+211)+'_hrT2.nii'\n",
    "    \n",
    "    validation_sample_from_target_domain = sitk.ReadImage(validation_samples_from_target_domain[i])\n",
    "    \n",
    "    (center_x,center_y) = finding_center_z_axis(validation_sample_from_target_domain)\n",
    "    cropped_validation_sample_from_target_domain = center_crop_on_validation_sample(validation_sample_from_target_domain, center_x, center_y)\n",
    "\n",
    "    normalised_validation_sample_from_target_domain = sitk.RescaleIntensity(cropped_validation_sample_from_target_domain,outputMinimum=0.0, outputMaximum=255.0)\n",
    "    sitk.WriteImage(normalised_validation_sample_from_target_domain, save_path_for_preprocessed_validation_samples_from_target_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26175b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_training_samples_from_source_domain = glob.glob(path_to_preprocessed_training_samples_from_source_domain+'*')\n",
    "preprocessed_training_labels_from_source_domain = glob.glob(path_to_preprocessed_training_labels_from_source_domain+'*')\n",
    "preprocessed_training_samples_from_target_domain = glob.glob(path_to_preprocessed_training_samples_from_target_domain+'*')\n",
    "preprocessed_validation_samples_from_target_domain = glob.glob(path_to_preprocessed_validation_samples_from_target_domain+'*')\n",
    "\n",
    "print('Number of preprocessed training samples from source domain (ceT1) is: ' + str(len(preprocessed_training_samples_from_source_domain)))\n",
    "print('Number of preprocessed training labels from source domain (ceT1) is: ' + str(len(preprocessed_training_labels_from_source_domain)))\n",
    "print('Number of preprocessed training samples from target domain (hrT2) is: ' + str(len(preprocessed_training_samples_from_target_domain)))\n",
    "print('Number of preprocessed validation samples from target domain (hrT2) is: ' + str(len(preprocessed_validation_samples_from_target_domain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed training sample from source domain (ceT1)\n",
    "img_load = nib.load(preprocessed_training_samples_from_source_domain[0]).get_fdata()\n",
    "labels_load = nib.load(preprocessed_training_labels_from_source_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,44+i])\n",
    "    plt.imshow(labels_load[:,:,44+i],alpha=0.5)\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed training sample from target domain (hrT2)\n",
    "img_load = nib.load(preprocessed_training_samples_from_target_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,29+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed validation sample from target domain (hrT2)\n",
    "img_load = nib.load(preprocessed_validation_samples_from_target_domain[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,29+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f00ecf",
   "metadata": {},
   "source": [
    "## Example of fake hrT2 volume generated by CUT model using real ceT1 volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed validation sample from target domain (hrT2)\n",
    "source_dir = 'dataset/fake_hrT2_MRI_scan/fake_hrT2_volume/'\n",
    "fake_hrT2_volume = glob.glob(source_dir+'*')\n",
    "\n",
    "img_load = nib.load(fake_hrT2_volume[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,44+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e1f11",
   "metadata": {},
   "source": [
    "The code regarding CUT model and nnU-Net model training and inferencing can be found on https://drive.google.com/drive/folders/1oZbSLDman28BaQufGXKWHdgpc72lYlmP?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efd3f9",
   "metadata": {},
   "source": [
    "## Reducing tumour signal on generated hrT2 volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1378ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_base_dir = 'dataset/fake_hrT2_MRI_scan/fake_hrT2_volume_with_reduced_tumour_signal/'\n",
    "\n",
    "postprocessed_training_labels_from_source_domain = glob.glob(path_to_preprocessed_training_labels_from_source_domain+'*')\n",
    "\n",
    "for i in range(len(postprocessed_training_labels_from_source_domain)):\n",
    "    labels_load = nib.load(postprocessed_training_labels_from_source_domain[i]).get_fdata()\n",
    "    vs_label = np.where(labels_load == 1, 0.5,1)\n",
    "\n",
    "    original_volume_load = nib.load(fake_hrT2_volume[i])\n",
    "\n",
    "    reduce_volume_np = np.multiply(original_volume_load.get_fdata(), vs_label)\n",
    "\n",
    "    destination = destination_base_dir+'crossmoda_'+str(i)+'_fake_hrT2_with_reduced_signal.nii'\n",
    "\n",
    "    new_volume = nib.Nifti1Image(reduce_volume_np, original_volume_load.affine)\n",
    "\n",
    "    nib.save(new_volume, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed validation sample from target domain (hrT2)\n",
    "fake_hrT2_with_reduced_signal = glob.glob(destination_base_dir+'*')\n",
    "img_load = nib.load(fake_hrT2_with_reduced_signal[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,44+i])\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac18839",
   "metadata": {},
   "source": [
    "## Image Postprocessing on prediction mask generated ny nnU-Net segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6324f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_z_range_post_processed(sample):\n",
    "    nda = sitk.GetArrayFromImage(sample)\n",
    "    x = np.sum(nda,axis = (1,2))\n",
    "    x_arg = np.argwhere(x>0)\n",
    "    s = x_arg[0]\n",
    "    e = x_arg[-1]\n",
    "    expand = (120-len(x_arg))/2\n",
    "    if expand >= s:\n",
    "        [ns,ne] = [0,120]\n",
    "    elif (expand + 1 + e) >= x.shape[0]:\n",
    "        [ns,ne] = [x.shape[0]-120,x.shape[0]]\n",
    "    else:\n",
    "        ns = int((s-np.floor(expand))[0])\n",
    "        ne = int((e+np.ceil(expand)+1)[0])\n",
    "    return (ns,ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09173d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncrop(sample, center_x, center_y, prediction):\n",
    "    left = int(center_x - np.ceil(368/2))\n",
    "    bottom = int(center_y - np.ceil(368/2))\n",
    "    uncrop_prediction = np.zeros(sitk.GetArrayFromImage(sample).shape)\n",
    "    center_cropped_sample = sample[left:left+368, bottom:bottom+368, :]\n",
    "    (ns, ne) = get_new_z_range_post_processed(center_cropped_sample)\n",
    "    prediction_nda = sitk.GetArrayFromImage(prediction)\n",
    "    uncrop_prediction[ns:ne, bottom:bottom+368, left:left+368] = prediction_nda\n",
    "    return uncrop_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffde281",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_masks = glob.glob(path_to_raw_prediction_mask+'*')\n",
    "postprocessed_prediction_masks = glob.glob(path_to_postprocessed_prediction_mask+'*')\n",
    "\n",
    "print('Number of prediction masks is: ' + str(len(prediction_masks)))\n",
    "print('Number of prediction masks is: ' + str(len(postprocessed_prediction_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random preprocessed prediction mask generated by nnU-Net\n",
    "img_load = nib.load(preprocessed_validation_samples_from_target_domain[0]).get_fdata()\n",
    "labels_load = nib.load(prediction_masks[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,24+i])\n",
    "    plt.imshow(labels_load[:,:,24+i],alpha=0.5)\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prediction_masks)):\n",
    "    \n",
    "    save_path_for_postprocessed_prediction_mask = path_to_postprocessed_prediction_mask + 'crossmoda_'+str(i+211)+'_Label.nii'\n",
    "\n",
    "    validation_sample_before_cropping = sitk.ReadImage(validation_samples_from_target_domain[i])\n",
    "    prediction = sitk.ReadImage(prediction_masks[i])\n",
    "\n",
    "    (center_x,center_y) = finding_center_z_axis(validation_sample_before_cropping)\n",
    "\n",
    "    uncrop_prediction = uncrop(validation_sample_before_cropping, center_x, center_y, prediction)\n",
    "\n",
    "    new_prediction_volume = sitk.GetImageFromArray(uncrop_prediction, isVector=False)\n",
    "\n",
    "\n",
    "    new_spacing = validation_sample_before_cropping.GetSpacing()\n",
    "    \n",
    "    new_prediction_volume.SetSpacing(new_spacing)\n",
    "\n",
    "    sitk.WriteImage(new_prediction_volume, save_path_for_postprocessed_prediction_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c697ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_masks = glob.glob(path_to_raw_prediction_mask+'*')\n",
    "postprocessed_prediction_masks = glob.glob(path_to_postprocessed_prediction_mask+'*')\n",
    "\n",
    "print('Number of prediction masks is: ' + str(len(prediction_masks)))\n",
    "print('Number of prediction masks is: ' + str(len(postprocessed_prediction_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13beb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display random postprocessed validation sample from target domain (hrT2)\n",
    "img_load = nib.load(validation_samples_from_target_domain[0]).get_fdata()\n",
    "labels_load = nib.load(postprocessed_prediction_masks[0]).get_fdata()\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4,i + 1)\n",
    "    plt.imshow(img_load[:,:,24+i])\n",
    "    plt.imshow(labels_load[:,:,24+i],alpha=0.5)\n",
    "    plt.gcf().set_size_inches(200, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9daea56",
   "metadata": {},
   "source": [
    "## Framework Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_experiment_result_path = 'results/baseline_experiment_result.json'\n",
    "replicate_work_result_path = 'results/replicate_work_result.json'\n",
    "proposed_work_result_path = 'results/proposed_work_result.json'\n",
    "\n",
    "with open(baseline_experiment_result_path, 'r') as x:\n",
    "    baseline_experiment_result = json.load(x)\n",
    "\n",
    "with open(replicate_work_result_path, 'r') as y:\n",
    "    replicated_work_result = json.load(y)\n",
    "    \n",
    "with open(proposed_work_result_path, 'r') as z:\n",
    "    proposed_work_result = json.load(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dfc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_experiment_VS_ASSD = list(baseline_experiment_result['case']['VS_ASSD'].values())\n",
    "baseline_experiment_VS_Dice = list(baseline_experiment_result['case']['VS_Dice'].values())\n",
    "baseline_experiment_Cochlea_ASSD = list(baseline_experiment_result['case']['Cochlea_ASSD'].values())\n",
    "baseline_experiment_Cochlea_Dice = list(baseline_experiment_result['case']['Cochlea_Dice'].values())\n",
    "baseline_experiment_Mean_Dice = list(baseline_experiment_result['case']['Mean_Dice'].values())\n",
    "\n",
    "replicated_work_VS_ASSD = list(replicated_work_result['case']['VS_ASSD'].values())\n",
    "replicated_work_VS_Dice = list(replicated_work_result['case']['VS_Dice'].values())\n",
    "replicated_work_Cochlea_ASSD = list(replicated_work_result['case']['Cochlea_ASSD'].values())\n",
    "replicated_work_Cochlea_Dice = list(replicated_work_result['case']['Cochlea_Dice'].values())\n",
    "replicated_work_Mean_Dice = list(replicated_work_result['case']['Mean_Dice'].values())\n",
    "\n",
    "proposed_work_VS_ASSD = list(proposed_work_result['case']['VS_ASSD'].values())\n",
    "proposed_work_VS_Dice = list(proposed_work_result['case']['VS_Dice'].values())\n",
    "proposed_work_Cochlea_ASSD = list(proposed_work_result['case']['Cochlea_ASSD'].values())\n",
    "proposed_work_Cochlea_Dice = list(proposed_work_result['case']['Cochlea_Dice'].values())\n",
    "proposed_work_Mean_Dice = list(proposed_work_result['case']['Mean_Dice'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca77bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the aggregates result from baselin experiment\n",
    "baseline_result_table = pd.DataFrame.from_dict(baseline_experiment_result['aggregates'])\n",
    "del baseline_result_table['gt_fname']\n",
    "del baseline_result_table['pred_fname']\n",
    "baseline_result_table[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b561648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the aggregates result from baselin experiment\n",
    "replicated_work_result_table = pd.DataFrame.from_dict(replicated_work_result['aggregates'])\n",
    "del replicated_work_result_table['gt_fname']\n",
    "del replicated_work_result_table['pred_fname']\n",
    "replicated_work_result_table[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the aggregates result from baselin experiment\n",
    "proposed_work_result_table = pd.DataFrame.from_dict(proposed_work_result['aggregates'])\n",
    "del proposed_work_result_table['gt_fname']\n",
    "del proposed_work_result_table['pred_fname']\n",
    "proposed_work_result_table[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a713c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_VS_ASSD = pd.DataFrame({'DA without self training':replicated_work_VS_ASSD,'DA with self training':proposed_work_VS_ASSD})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot(data=composite_VS_ASSD)\n",
    "sns.swarmplot(data=composite_VS_ASSD, color=\"w\", alpha=0.8)\n",
    "ax.set_title(\"Average symmetric surface distance comparison on vestibular schwannoma segmentation\")\n",
    "ax.set_ylabel(\"ASSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_VS_Dice = pd.DataFrame({'DA without self training':replicated_work_VS_Dice,'DA with self training':proposed_work_VS_Dice})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot(data=composite_VS_Dice)\n",
    "sns.swarmplot(data=composite_VS_Dice, color=\"w\", alpha=0.8)\n",
    "ax.set_title(\"Dice similarity coefficient comparison on vestibular schwannoma segmentation\")\n",
    "ax.set_ylabel(\"DSC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d973dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_Cochlea_Dice = pd.DataFrame({'DA without self training':replicated_work_Cochlea_Dice,'DA with self training':proposed_work_Cochlea_Dice})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot(data=composite_Cochlea_Dice)\n",
    "sns.swarmplot(data=composite_Cochlea_Dice, color=\"w\", alpha=0.8)\n",
    "ax.set_title(\"Dice similarity coefficient comparison on bilateral cochlea segmentation\")\n",
    "ax.set_ylabel(\"DSC\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
